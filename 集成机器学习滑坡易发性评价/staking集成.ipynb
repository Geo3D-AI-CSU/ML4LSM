{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zs\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve,  roc_auc_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error #MSE\n",
    "from sklearn.metrics import mean_absolute_error #MAE\n",
    "from sklearn.metrics import r2_score#R 2\n",
    "from sklearn.metrics import cohen_kappa_score#Kappa\n",
    "\n",
    "from sklearn import datasets  \n",
    "from sklearn import model_selection  \n",
    "from mlxtend.classifier import StackingClassifier \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Statistics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def accuracy(clf,x_train,x_test,y_train,y_test):\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"acc_test=\", accuracy_score(y_test, y_pred))\n",
    "    y_pred = clf.predict(x_train)\n",
    "    print(\"acc_train=\", accuracy_score(y_train, y_pred))\n",
    "#分类报告\n",
    "def report (modle,x_train,y_train):\n",
    "    y_pred=modle.predict(x_train)\n",
    "    reports=classification_report(y_train,y_pred)\n",
    "    print(\"classification report：\\n\", reports)\n",
    "\n",
    "def cross_accuracy(clf,x_train,x_test,y_train,y_test):\n",
    "    scores=cross_val_score(clf,x_test,y_test,cv=5,scoring='accuracy')\n",
    "    print(\"acc_cv_test=\",scores.mean())\n",
    "    scores=cross_val_score(clf,x_train,y_train,cv=5,scoring='accuracy')\n",
    "    print(\"acc_cv_train=\",scores.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.65522594e+01 2.65522594e+01 7.99000000e+03 ... 1.00677980e+00\n",
      "  1.40000000e+03 1.20000000e+01]\n",
      " [2.69640179e+01 2.69640179e+01 7.99000000e+03 ... 1.00377230e+00\n",
      "  1.40000000e+03 1.20000000e+01]\n",
      " [2.46682053e+01 2.46682053e+01 7.99000000e+03 ... 1.00395260e+00\n",
      "  1.40000000e+03 1.20000000e+01]\n",
      " ...\n",
      " [2.38685815e+03 2.58289868e+03 8.65500000e+03 ... 1.08457950e+00\n",
      "  1.40000000e+03 9.00000000e+00]\n",
      " [1.99688309e+02 5.48773003e+01 5.85900000e+03 ... 1.04616280e+00\n",
      "  1.20000000e+03 1.10000000e+01]\n",
      " [6.57715186e+03 7.15558740e+03 8.46600000e+03 ... 1.09718880e+00\n",
      "  1.60000000e+03 1.00000000e+00]] [1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(r'E:/huan/ml/data/new/new01.csv')\n",
    "data = data.fillna(0)\n",
    "X = data.iloc[:,np.r_[1:13,16:17]].values\n",
    "Y = data['remote1'].values \n",
    "print(X,Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, train_size=0.8)\n",
    "x_train, x_train_lr, y_train, y_train_lr = train_test_split(\n",
    "    x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GradientBoostingClassifier,Accuracy 0.766820:\n",
      "precision=0.687049 recall=0.532165 f1score=0.599769\n",
      "MSE=0.233180 MAE=0.233180 RMSE=0.482887 R2=-0.057393 Kappa=0.438976\n",
      "classification report：\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84     10972\n",
      "           1       0.69      0.53      0.60      5363\n",
      "\n",
      "    accuracy                           0.77     16335\n",
      "   macro avg       0.74      0.71      0.72     16335\n",
      "weighted avg       0.76      0.77      0.76     16335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoosting\n",
    "clf1=GradientBoostingClassifier(max_depth= 34, max_features=0.9, max_leaf_nodes=375, n_estimators=43)\n",
    "clf1.fit(x_train,y_train)\n",
    "y_test_pred = clf1.predict(x_test)\n",
    "print(\"Model GradientBoostingClassifier,Accuracy %0.6f:\"%(accuracy_score(y_test,y_test_pred)))\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1score = f1_score(y_test,y_test_pred)\n",
    "print(\"precision=%f recall=%f f1score=%f\"%(precision, recall, f1score))\n",
    "MSE=mean_squared_error(y_test,y_test_pred)\n",
    "MAE=mean_absolute_error(y_test,y_test_pred)\n",
    "RMSE=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "R2=r2_score(y_test,y_test_pred)\n",
    "Kappa=cohen_kappa_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE=%f MAE=%f RMSE=%f R2=%f Kappa=%f\"%(MSE,MAE,RMSE,R2,Kappa))\n",
    "report (clf1,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC of GBDT+LR is： 0.7578938921298763\n",
      "GBT+LR,Accuracy 0.718212:\n",
      "precision=0.577173 recall=0.529927 f1score=0.552542\n",
      "MSE=0.281788 MAE=0.281788 RMSE=0.530837 R2=-0.277811 Kappa=0.347441\n"
     ]
    }
   ],
   "source": [
    "# Integration of GBDT and LR models \n",
    "grd = clf1\n",
    "grd_enc = OneHotEncoder()\n",
    "grd_lm = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    " \n",
    "grd.fit(x_train, y_train)\n",
    "grd_enc.fit(grd.apply(x_train)[:, :, 0])\n",
    "grd_lm.fit(grd_enc.transform(grd.apply(x_train_lr)[:, :, 0]), y_train_lr)\n",
    " \n",
    "y_pred_grd_lm = grd_lm.predict_proba(\n",
    "    grd_enc.transform(grd.apply(x_test)[:, :, 0]))[:, 1]\n",
    "fpr_grd_lm, tpr_grd_lm, _ = roc_curve(y_test, y_pred_grd_lm)\n",
    "print(\"The AUC of GBDT+LR is：\", roc_auc_score(y_test, y_pred_grd_lm))\n",
    "\n",
    "y_testpred = grd_lm.predict(\n",
    "    grd_enc.transform(grd.apply(x_test)[:, :, 0]))    \n",
    "print(\"GBT+LR,Accuracy %0.6f:\"%(accuracy_score(y_test, y_testpred)))\n",
    "precision = precision_score(y_test, y_testpred)\n",
    "recall = recall_score(y_test, y_testpred)\n",
    "f1score = f1_score(y_test, y_testpred)\n",
    "print(\"precision=%f recall=%f f1score=%f\"%(precision, recall, f1score))\n",
    "MSE=mean_squared_error(y_test, y_testpred)\n",
    "MAE=mean_absolute_error(y_test, y_testpred)\n",
    "RMSE=np.sqrt(mean_squared_error(y_test, y_testpred))\n",
    "R2=r2_score(y_test, y_testpred)\n",
    "Kappa=cohen_kappa_score(y_test, y_testpred)\n",
    "print(\"MSE=%f MAE=%f RMSE=%f R2=%f Kappa=%f\"%(MSE,MAE,RMSE,R2,Kappa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RandomForestClassifier,Accuracy 0.724518:\n",
      "precision=0.632159 recall=0.384859 f1score=0.478442\n",
      "MSE=0.275482 MAE=0.275482 RMSE=0.524864 R2=-0.249217 Kappa=0.305996\n",
      "classification report：\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81     10972\n",
      "           1       0.63      0.38      0.48      5363\n",
      "\n",
      "    accuracy                           0.72     16335\n",
      "   macro avg       0.69      0.64      0.65     16335\n",
      "weighted avg       0.71      0.72      0.70     16335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "clf2=RandomForestClassifier(max_depth=20, max_features=0.8, max_leaf_nodes=45, n_estimators=1100)\n",
    "clf2.fit(x_train,y_train)\n",
    "y_test_pred = clf2.predict(x_test)\n",
    "print(\"Model RandomForestClassifier,Accuracy %0.6f:\"%(accuracy_score(y_test,y_test_pred)))\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test,y_test_pred)\n",
    "f1score = f1_score(y_test,y_test_pred)\n",
    "print(\"precision=%f recall=%f f1score=%f\"%(precision, recall, f1score))\n",
    "MSE=mean_squared_error(y_test,y_test_pred)\n",
    "MAE=mean_absolute_error(y_test,y_test_pred)\n",
    "RMSE=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "R2=r2_score(y_test,y_test_pred)\n",
    "Kappa=cohen_kappa_score(y_test, y_test_pred)\n",
    "print(\"MSE=%f MAE=%f RMSE=%f R2=%f Kappa=%f\"%(MSE,MAE,RMSE,R2,Kappa))\n",
    "report (clf2,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC of RF+LR is： 0.6946599667629888\n",
      "RF+LR,Accuracy 0.686134:\n",
      "precision=0.523137 recall=0.497483 f1score=0.509988\n",
      "MSE=0.313866 MAE=0.313866 RMSE=0.560237 R2=-0.423275 Kappa=0.279329\n"
     ]
    }
   ],
   "source": [
    "# Integration of RF and LR models\n",
    "rf = clf2\n",
    "rf_enc = OneHotEncoder()\n",
    "rf_lm = LogisticRegression(solver='lbfgs', max_iter=1000)    \n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "rf_enc.fit(rf.apply(x_train))\n",
    "rf_lm.fit(rf_enc.transform(rf.apply(x_train_lr)), y_train_lr)\n",
    "     \n",
    "y_pred_rf_lm = rf_lm.predict_proba(rf_enc.transform(rf.apply(x_test)))[:, 1]\n",
    "fpr_rf_lm, tpr_rf_lm, _ = roc_curve(y_test, y_pred_rf_lm)\n",
    "print(\"The AUC of RF+LR is：\", roc_auc_score(y_test, y_pred_rf_lm))\n",
    "\n",
    "y_testpred = rf_lm.predict(rf_enc.transform(rf.apply(x_test)))    \n",
    "print(\"RF+LR,Accuracy %0.6f:\"%(accuracy_score(y_test, y_testpred)))\n",
    "precision = precision_score(y_test, y_testpred)\n",
    "recall = recall_score(y_test, y_testpred)\n",
    "f1score = f1_score(y_test, y_testpred)\n",
    "print(\"precision=%f recall=%f f1score=%f\"%(precision, recall, f1score))\n",
    "MSE=mean_squared_error(y_test, y_testpred)\n",
    "MAE=mean_absolute_error(y_test, y_testpred)\n",
    "RMSE=np.sqrt(mean_squared_error(y_test, y_testpred))\n",
    "R2=r2_score(y_test, y_testpred)\n",
    "Kappa=cohen_kappa_score(y_test, y_testpred)\n",
    "print(\"MSE=%f MAE=%f RMSE=%f R2=%f Kappa=%f\"%(MSE,MAE,RMSE,R2,Kappa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model XGBClassifier,Accuracy 0.773370:\n",
      "precision=0.697409 recall=0.547082 f1score=0.613166\n",
      "MSE=0.226630 MAE=0.226630 RMSE=0.476057 R2=-0.027690 Kappa=0.456194\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "clf4=xgb.XGBClassifier(max_depth=9, n_estimators=145, reg_alpha=0.9, reg_lambda=0.8,eval_metric=['logloss','auc','error'],learning_rate=0.1,n_jobs=-1)\n",
    "clf4.fit(x_train,y_train)\n",
    "y_test_pred = clf4.predict(x_test)\n",
    "print(\"Model XGBClassifier,Accuracy %0.6f:\"%(accuracy_score(y_test,y_test_pred)))\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1score = f1_score(y_test,y_test_pred)\n",
    "print(\"precision=%f recall=%f f1score=%f\"%(precision, recall, f1score))\n",
    "MSE=mean_squared_error(y_test,y_test_pred)\n",
    "MAE=mean_absolute_error(y_test,y_test_pred)\n",
    "RMSE=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "R2=r2_score(y_test,y_test_pred)\n",
    "Kappa=cohen_kappa_score(y_test, y_test_pred)\n",
    "print(\"MSE=%f MAE=%f RMSE=%f R2=%f Kappa=%f\"%(MSE,MAE,RMSE,R2,Kappa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC of XGB+LR is： 0.767866202098077\n",
      "xgboost+LR,Accuracy 0.719988:\n",
      "precision=0.578695 recall=0.540929 f1score=0.559175\n",
      "MSE=0.280012 MAE=0.280012 RMSE=0.529162 R2=-0.269760 Kappa=0.354350\n"
     ]
    }
   ],
   "source": [
    "# Integration of xgboost and LR models\n",
    "xgb = clf4\n",
    "xgb_enc = OneHotEncoder()\n",
    "xgb_lm = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    " \n",
    "xgb.fit(x_train, y_train)\n",
    "xgb_enc.fit(xgb.apply(x_train))\n",
    "xgb_lm.fit(xgb_enc.transform(xgb.apply(x_train_lr)), y_train_lr)\n",
    " \n",
    "y_pred_xgb_lm = xgb_lm.predict_proba(\n",
    "    xgb_enc.transform(xgb.apply(x_test)))[:, 1]\n",
    "fpr_xgb_lm, tpr_xgb_lm, _ = roc_curve(y_test, y_pred_xgb_lm)\n",
    "print(\"The AUC of XGB+LR is：\", roc_auc_score(y_test, y_pred_xgb_lm))\n",
    "\n",
    "y_testpred = xgb_lm.predict(\n",
    "    xgb_enc.transform(xgb.apply(x_test))) \n",
    "print(\"xgboost+LR,Accuracy %0.6f:\"%(accuracy_score(y_test, y_testpred)))\n",
    "precision = precision_score(y_test, y_testpred)\n",
    "recall = recall_score(y_test, y_testpred)\n",
    "f1score = f1_score(y_test, y_testpred)\n",
    "print(\"precision=%f recall=%f f1score=%f\"%(precision, recall, f1score))\n",
    "MSE=mean_squared_error(y_test, y_testpred)\n",
    "MAE=mean_absolute_error(y_test, y_testpred)\n",
    "RMSE=np.sqrt(mean_squared_error(y_test, y_testpred))\n",
    "R2=r2_score(y_test, y_testpred)\n",
    "Kappa=cohen_kappa_score(y_test, y_testpred)\n",
    "print(\"MSE=%f MAE=%f RMSE=%f R2=%f Kappa=%f\"%(MSE,MAE,RMSE,R2,Kappa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r'E:/huan/ml/data/new/zjjdata.csv')\n",
    "#data = data.fillna(0)\n",
    "#x_fearures_new1 = data.iloc[:,np.r_[1:13,16:17]].values\n",
    "#y_label_new1_predict = clf2.predict_proba(x_fearures_new1)\n",
    "#y_predict1 = y_label_new1_predict[:,1]\n",
    "#print('The New point 1 predict class:\\n',y_predict1)\n",
    "#result = pd.DataFrame(y_predict1)\n",
    "#data['rf']=result\n",
    "##result=pd.DataFrame(columns=['yuce'], data=y_predict1)\n",
    "#data.to_csv(r'E:/huan/ml/data/new/zjjdata.csv',mode = 'a',index=False)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r'E:/huan/ml/data/new/zjjdata.csv')\n",
    "#data = data.fillna(0)\n",
    "#x_fearures_new1 = data.iloc[:,np.r_[1:13,16:17]].values\n",
    "#y_label_new1_predict = clf1.predict_proba(x_fearures_new1)\n",
    "#y_predict1 = y_label_new1_predict[:,1]\n",
    "#print('The New point 1 predict class:\\n',y_predict1)\n",
    "#result = pd.DataFrame(y_predict1)\n",
    "#data['gbdt']=result\n",
    "##result=pd.DataFrame(columns=['yuce'], data=y_predict1)\n",
    "#data.to_csv(r'E:/huan/ml/data/new/zjjdata.csv',mode = 'a',index=False)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r'E:/huan/ml/data/new/zjjdata.csv')\n",
    "#data = data.fillna(0)\n",
    "#x_fearures_new1 = data.iloc[:,np.r_[1:13,16:17]].values\n",
    "#y_label_new1_predict = clf4.predict_proba(x_fearures_new1)\n",
    "#y_predict1 = y_label_new1_predict[:,1]\n",
    "#print('The New point 1 predict class:\\n',y_predict1)\n",
    "#result = pd.DataFrame(y_predict1)\n",
    "#data['xgb']=result\n",
    "##result=pd.DataFrame(columns=['yuce'], data=y_predict1)\n",
    "#data.to_csv(r'E:/huan/ml/data/new/zjjdata.csv',mode = 'a',index=False)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New point 1 predict class:\n",
      " [0.56189825 0.09115646 0.01632896 ... 0.34604173 0.06106415 0.00063088]\n",
      "         OBJECTID       rivers         roads  NDVI      aspect     plane  \\\n",
      "0               1  5213.345703   5511.335449  8172  134.573517  0.181283   \n",
      "1               2     0.000000      0.000000     0    0.000000  0.000000   \n",
      "2               3     9.365650      9.365650  7990  280.426361  0.809007   \n",
      "3               4  5140.192383   5527.872559  8172  137.206558  0.580557   \n",
      "4               5  5100.440918   5601.580566  8172  118.792221  0.319655   \n",
      "...           ...          ...           ...   ...         ...       ...   \n",
      "1166578   1166579  4473.856934  11240.130859     0    0.000000  0.000000   \n",
      "1166579   1166580  4503.968750  11278.761719     0    0.000000  0.000000   \n",
      "1166580   1166581  4535.937988  11318.237305     0    0.000000  0.000000   \n",
      "1166581   1166582  4569.834473  11358.653320     0    0.000000  0.000000   \n",
      "1166582   1166583  4599.093750  11392.606445     0    0.000000  0.000000   \n",
      "\n",
      "          profile        twi  landuse  altitude  ...      slope           x  \\\n",
      "0        0.069249  11.039824       20       337  ...  23.429737  110.525986   \n",
      "1        0.000000   0.000000        0         0  ...   0.000000  110.526916   \n",
      "2       -0.049128  10.789610       80       384  ...  29.098499  110.460815   \n",
      "3       -0.004214   7.271912       20       385  ...  32.018856  110.525986   \n",
      "4        0.239198  10.602624       20       330  ...  33.861389  110.526916   \n",
      "...           ...        ...      ...       ...  ...        ...         ...   \n",
      "1166578  0.252147   2.301355        0      1491  ...   5.717745  110.106079   \n",
      "1166579  0.000000   0.000000        0         0  ...   0.000000  110.107017   \n",
      "1166580  0.000000   0.000000        0         0  ...   0.000000  110.107948   \n",
      "1166581  0.000000   0.000000        0         0  ...   0.000000  110.108879   \n",
      "1166582  0.000000   0.000000        0         0  ...   0.000000  110.109810   \n",
      "\n",
      "                 y  lithology  soil  remote1        rf      gbdt       xgb  \\\n",
      "0        28.878027          3     2        0  0.399589  0.351123  0.504162   \n",
      "1        28.878027          0     0        0  0.095146  0.198931  0.246241   \n",
      "2        28.878843         12     2        0  0.260428  0.541188  0.478389   \n",
      "3        28.878843          3     2        0  0.376948  0.212642  0.419941   \n",
      "4        28.878843          3     2        0  0.379857  0.389986  0.375115   \n",
      "...            ...        ...   ...      ...       ...       ...       ...   \n",
      "1166578  29.791431          0     0        0  0.558989  0.439565  0.131050   \n",
      "1166579  29.791431          0     0        0  0.234883  0.141504  0.084333   \n",
      "1166580  29.791431          0     0        0  0.281449  0.142588  0.086605   \n",
      "1166581  29.791431          0     0        0  0.243570  0.141504  0.088240   \n",
      "1166582  29.791431          0     0        0  0.200634  0.065393  0.024598   \n",
      "\n",
      "             rflr  \n",
      "0        0.561898  \n",
      "1        0.091156  \n",
      "2        0.016329  \n",
      "3        0.137555  \n",
      "4        0.004478  \n",
      "...           ...  \n",
      "1166578  0.720115  \n",
      "1166579  0.019140  \n",
      "1166580  0.346042  \n",
      "1166581  0.061064  \n",
      "1166582  0.000631  \n",
      "\n",
      "[1166583 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'E:/huan/ml/data/new/zjjdata.csv')\n",
    "data = data.fillna(0)\n",
    "x_fearures_new1 = data.iloc[:,np.r_[1:13,16:17]].values\n",
    "y_label_new1_predict = rf_lm.predict_proba(\n",
    "    rf_enc.transform(rf.apply(x_fearures_new1)))\n",
    "y_predict1 = y_label_new1_predict[:,1]\n",
    "print('The New point 1 predict class:\\n',y_predict1)\n",
    "result = pd.DataFrame(y_predict1)\n",
    "data['rflr']=result\n",
    "#result=pd.DataFrame(columns=['yuce'], data=y_predict1)\n",
    "data.to_csv('E:/huan/ml/data/new/zjjdata.csv',mode = 'a',index=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New point 1 predict class:\n",
      " [0.85059018 0.11779791 0.0875024  ... 0.32355981 0.04724984 0.00339247]\n",
      "         OBJECTID       rivers         roads  NDVI      aspect     plane  \\\n",
      "0               1  5213.345703   5511.335449  8172  134.573517  0.181283   \n",
      "1               2     0.000000      0.000000     0    0.000000  0.000000   \n",
      "2               3     9.365650      9.365650  7990  280.426361  0.809007   \n",
      "3               4  5140.192383   5527.872559  8172  137.206558  0.580557   \n",
      "4               5  5100.440918   5601.580566  8172  118.792221  0.319655   \n",
      "...           ...          ...           ...   ...         ...       ...   \n",
      "1166578   1166579  4473.856934  11240.130859     0    0.000000  0.000000   \n",
      "1166579   1166580  4503.968750  11278.761719     0    0.000000  0.000000   \n",
      "1166580   1166581  4535.937988  11318.237305     0    0.000000  0.000000   \n",
      "1166581   1166582  4569.834473  11358.653320     0    0.000000  0.000000   \n",
      "1166582   1166583  4599.093750  11392.606445     0    0.000000  0.000000   \n",
      "\n",
      "          profile        twi  landuse  altitude  ...          y  lithology  \\\n",
      "0        0.069249  11.039824       20       337  ...  28.878027          3   \n",
      "1        0.000000   0.000000        0         0  ...  28.878027          0   \n",
      "2       -0.049128  10.789610       80       384  ...  28.878843         12   \n",
      "3       -0.004214   7.271912       20       385  ...  28.878843          3   \n",
      "4        0.239198  10.602624       20       330  ...  28.878843          3   \n",
      "...           ...        ...      ...       ...  ...        ...        ...   \n",
      "1166578  0.252147   2.301355        0      1491  ...  29.791431          0   \n",
      "1166579  0.000000   0.000000        0         0  ...  29.791431          0   \n",
      "1166580  0.000000   0.000000        0         0  ...  29.791431          0   \n",
      "1166581  0.000000   0.000000        0         0  ...  29.791431          0   \n",
      "1166582  0.000000   0.000000        0         0  ...  29.791431          0   \n",
      "\n",
      "         soil  remote1        rf      gbdt       xgb      rflr     xgblr  \\\n",
      "0           2        0  0.399589  0.351123  0.504162  0.561898  0.561898   \n",
      "1           0        0  0.095146  0.198931  0.246241  0.091156  0.091156   \n",
      "2           2        0  0.260428  0.541188  0.478389  0.016329  0.016329   \n",
      "3           2        0  0.376948  0.212642  0.419941  0.137555  0.137555   \n",
      "4           2        0  0.379857  0.389986  0.375115  0.004478  0.004478   \n",
      "...       ...      ...       ...       ...       ...       ...       ...   \n",
      "1166578     0        0  0.558989  0.439565  0.131050  0.720115  0.720115   \n",
      "1166579     0        0  0.234883  0.141504  0.084333  0.019140  0.019140   \n",
      "1166580     0        0  0.281449  0.142588  0.086605  0.346042  0.346042   \n",
      "1166581     0        0  0.243570  0.141504  0.088240  0.061064  0.061064   \n",
      "1166582     0        0  0.200634  0.065393  0.024598  0.000631  0.000631   \n",
      "\n",
      "           gbdtlr  \n",
      "0        0.850590  \n",
      "1        0.117798  \n",
      "2        0.087502  \n",
      "3        0.315670  \n",
      "4        0.239325  \n",
      "...           ...  \n",
      "1166578  0.119488  \n",
      "1166579  0.026584  \n",
      "1166580  0.323560  \n",
      "1166581  0.047250  \n",
      "1166582  0.003392  \n",
      "\n",
      "[1166583 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'E:/huan/ml/data/new/zjjdata.csv')\n",
    "data = data.fillna(0)\n",
    "x_fearures_new1 = data.iloc[:,np.r_[1:13,16:17]].values\n",
    "#y_label_new1_predict = grd_lm.predict_proba(grd_enc.transform(grd.apply(x_fearures_new1)))[:, 1]\n",
    "y_label_new1_predict = grd_lm.predict_proba(grd_enc.transform(grd.apply(x_fearures_new1)[:, :, 0]))\n",
    "y_predict1 = y_label_new1_predict[:,1]\n",
    "print('The New point 1 predict class:\\n',y_predict1)\n",
    "result = pd.DataFrame(y_predict1)\n",
    "data['gbdtlr']=result\n",
    "#result=pd.DataFrame(columns=['yuce'], data=y_predict1)\n",
    "data.to_csv(r'E:/huan/ml/data/new/zjjdata.csv',mode = 'a',index=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New point 1 predict class:\n",
      " [0.85059018 0.11779791 0.0875024  ... 0.32355981 0.04724984 0.00339247]\n",
      "         OBJECTID       rivers         roads  NDVI      aspect     plane  \\\n",
      "0               1  5213.345703   5511.335449  8172  134.573517  0.181283   \n",
      "1               2     0.000000      0.000000     0    0.000000  0.000000   \n",
      "2               3     9.365650      9.365650  7990  280.426361  0.809007   \n",
      "3               4  5140.192383   5527.872559  8172  137.206558  0.580557   \n",
      "4               5  5100.440918   5601.580566  8172  118.792221  0.319655   \n",
      "...           ...          ...           ...   ...         ...       ...   \n",
      "1166578   1166579  4473.856934  11240.130859     0    0.000000  0.000000   \n",
      "1166579   1166580  4503.968750  11278.761719     0    0.000000  0.000000   \n",
      "1166580   1166581  4535.937988  11318.237305     0    0.000000  0.000000   \n",
      "1166581   1166582  4569.834473  11358.653320     0    0.000000  0.000000   \n",
      "1166582   1166583  4599.093750  11392.606445     0    0.000000  0.000000   \n",
      "\n",
      "          profile        twi  landuse  altitude  ...  lithology  soil  \\\n",
      "0        0.069249  11.039824       20       337  ...          3     2   \n",
      "1        0.000000   0.000000        0         0  ...          0     0   \n",
      "2       -0.049128  10.789610       80       384  ...         12     2   \n",
      "3       -0.004214   7.271912       20       385  ...          3     2   \n",
      "4        0.239198  10.602624       20       330  ...          3     2   \n",
      "...           ...        ...      ...       ...  ...        ...   ...   \n",
      "1166578  0.252147   2.301355        0      1491  ...          0     0   \n",
      "1166579  0.000000   0.000000        0         0  ...          0     0   \n",
      "1166580  0.000000   0.000000        0         0  ...          0     0   \n",
      "1166581  0.000000   0.000000        0         0  ...          0     0   \n",
      "1166582  0.000000   0.000000        0         0  ...          0     0   \n",
      "\n",
      "         remote1        rf      gbdt       xgb      rflr     xgblr    gbdtlr  \\\n",
      "0              0  0.399589  0.351123  0.504162  0.561898  0.561898  0.850590   \n",
      "1              0  0.095146  0.198931  0.246241  0.091156  0.091156  0.117798   \n",
      "2              0  0.260428  0.541188  0.478389  0.016329  0.016329  0.087502   \n",
      "3              0  0.376948  0.212642  0.419941  0.137555  0.137555  0.315670   \n",
      "4              0  0.379857  0.389986  0.375115  0.004478  0.004478  0.239325   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "1166578        0  0.558989  0.439565  0.131050  0.720115  0.720115  0.119488   \n",
      "1166579        0  0.234883  0.141504  0.084333  0.019140  0.019140  0.026584   \n",
      "1166580        0  0.281449  0.142588  0.086605  0.346042  0.346042  0.323560   \n",
      "1166581        0  0.243570  0.141504  0.088240  0.061064  0.061064  0.047250   \n",
      "1166582        0  0.200634  0.065393  0.024598  0.000631  0.000631  0.003392   \n",
      "\n",
      "           xgblr1  \n",
      "0        0.850590  \n",
      "1        0.117798  \n",
      "2        0.087502  \n",
      "3        0.315670  \n",
      "4        0.239325  \n",
      "...           ...  \n",
      "1166578  0.119488  \n",
      "1166579  0.026584  \n",
      "1166580  0.323560  \n",
      "1166581  0.047250  \n",
      "1166582  0.003392  \n",
      "\n",
      "[1166583 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'E:/huan/ml/data/new/zjjdata.csv')\n",
    "data = data.fillna(0)\n",
    "x_fearures_new1 = data.iloc[:,np.r_[1:13,16:17]].values\n",
    "x_fearures_new1 = xgb_lm.predict_proba(\n",
    "    xgb_enc.transform(xgb.apply(x_fearures_new1)))\n",
    "y_predict1 = y_label_new1_predict[:,1]\n",
    "print('The New point 1 predict class:\\n',y_predict1)\n",
    "result = pd.DataFrame(y_predict1)\n",
    "data['xgblr1']=result\n",
    "#result=pd.DataFrame(columns=['yuce'], data=y_predict1)\n",
    "data.to_csv(r'E:/huan/ml/data/new/zjjdata.csv',mode = 'a',index=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "from sklearn import metrics\n",
    "import pylab as plt\n",
    "\n",
    "Font={'size':18, 'family':'Times New Roman'}\n",
    "\n",
    "y_probas1 = clf2.predict_proba(x_test)\n",
    "y_probas2 = clf1.predict_proba(x_test)\n",
    "y_probas3 = clf4.predict_proba(x_test)\n",
    "\n",
    "y_scores1 = y_probas1[:,1]\n",
    "y_scores2 = y_probas2[:,1]\n",
    "y_scores3 = y_probas3[:,1]\n",
    "\n",
    "fpr1,tpr1,thres1 = metrics.roc_curve(y_test, y_scores1,drop_intermediate=False)\n",
    "fpr2,tpr2,thres2 = metrics.roc_curve(y_test, y_scores2,drop_intermediate=False)\n",
    "fpr3,tpr3,thres3 = metrics.roc_curve(y_test, y_scores3,drop_intermediate=False)\n",
    "\n",
    "fpr4,tpr4,thres4 = roc_curve(y_test, y_pred_rf_lm)\n",
    "fpr5,tpr5,thres5 = roc_curve(y_test, y_pred_grd_lm)\n",
    "fpr6,tpr6,thres6 = roc_curve(y_test, y_pred_xgb_lm)\n",
    "\n",
    "roc_auc4 = metrics.auc(fpr1, tpr1)\n",
    "roc_auc5 = metrics.auc(fpr2, tpr2)\n",
    "roc_auc6 = metrics.auc(fpr3, tpr3)\n",
    "\n",
    "roc_auc1 = metrics.auc(fpr4, tpr4)\n",
    "roc_auc2 = metrics.auc(fpr5, tpr5)\n",
    "roc_auc3 = metrics.auc(fpr6, tpr6)\n",
    "\n",
    "print(roc_auc1,roc_auc2,roc_auc3,roc_auc4,roc_auc5,roc_auc6)\n",
    "  \n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr4, tpr4, 'b', label = 'RF = %0.4f' % roc_auc1, color='Red')\n",
    "plt.plot(fpr5, tpr5, 'b', label = 'GBDT = %0.4f' % roc_auc2, color='k')\n",
    "plt.plot(fpr5, tpr5, 'b', label = 'XGB = %0.4f' % roc_auc3, color='Blue')\n",
    "\n",
    "plt.plot(fpr1, tpr1, 'b', label = 'RF+LR = %0.4f' % roc_auc4, color='orange')\n",
    "plt.plot(fpr2, tpr2, 'b', label = 'GBDT+LR = %0.4f' % roc_auc5, color='Green')\n",
    "plt.plot(fpr3, tpr3, 'b', label = 'XGB+LR = %0.4f' % roc_auc6, color='purple')\n",
    "    \n",
    "plt.legend(loc = 'lower right', prop=Font)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate', Font)\n",
    "plt.xlabel('False Positive Rate', Font)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix. \n",
    "    \n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "   \n",
    "    print(cm)\n",
    "    fig, ax = plt.subplots(figsize=(12, 8),dpi=200)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                    fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "labels = ['0','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of confusion matrixs\n",
    "plot_confusion_matrix(y_test, clf1.predict(x_test), classes=labels, normalize=True,title='Normalized confusion matrix')\n",
    "plot_confusion_matrix(y_test, clf2.predict(x_test), classes=labels, normalize=True,title='Normalized confusion matrix')\n",
    "plot_confusion_matrix(y_test, clf4.predict(x_test), classes=labels, normalize=True,title='Normalized confusion matrix')\n",
    "plot_confusion_matrix(y_test, grd_lm.predict(grd_enc.transform(grd.apply(x_test)[:, :, 0])), classes=labels, normalize=True,title='Normalized confusion matrix')\n",
    "plot_confusion_matrix(y_test, rf_lm.predict(rf_enc.transform(rf.apply(x_test))), classes=labels, normalize=True,title='Normalized confusion matrix')\n",
    "plot_confusion_matrix(y_test, xgb_lm.predict(xgb_enc.transform(xgb.apply(x_test))), classes=labels, normalize=True,title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
